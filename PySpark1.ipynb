{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlBMAiQf+eTTG20QbLgemj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsikrishna125/pyspark_practice1/blob/main/PySpark1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PySpark\n",
        "Reference https://www.youtube.com/watch?v=_C8kWso4ne4&t=947s\n",
        "\n",
        "---\n",
        "* other soucres for ETL\n",
        "1. for ETL with PETL https://github.com/dimgold/ETL_with_Python/blob/master/ETL_with_Python.ipynb\n",
        "2. top etl options in aws https://www.stitchdata.com/resources/aws-etl-tool/\n",
        "3. AWS GLUE https://hevodata.com/learn/aws-glue-tutorial/\n",
        "4. **IMP AWS GLUE ETL documentation and sample code https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-samples-legislators.html"
      ],
      "metadata": {
        "id": "yo-P8vyueDoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PySpark Basics"
      ],
      "metadata": {
        "id": "8usF0VnEFjZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKJLEVRWV4SD",
        "outputId": "c1032fde-b1f6-45d9-9ea5-9cb6cd61499a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "By6L8lJYWTvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "17wpzmlMXgC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName(\"parctice\").getOrCreate()"
      ],
      "metadata": {
        "id": "roR5K57-XxLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "gxo8xIw7X4TW",
        "outputId": "afd8c66c-7e95-4cf1-fb4a-a3213b0c6cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://cc13bc5fabe7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>parctice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ff9e8ae1550>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark=spark.read.csv('/content/sample_data/test1.csv')"
      ],
      "metadata": {
        "id": "DxYvVz5MYYNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4DiS4uFZZpz",
        "outputId": "973dcea6-e5bf-4eae-b981-b95f9b89d62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|      _c0|_c1|       _c2|   _c3|\n",
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.option('header','true').csv('/content/sample_data/test1.csv')"
      ],
      "metadata": {
        "id": "ti7JWa6RZlwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay8embRBao1f",
        "outputId": "249b687b-154c-4718-e48c-3bc58f7389f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_spark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAyQQ4TxaBP2",
        "outputId": "9dd196ba-dfd8-45c3-c14e-6b868e9fb92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI7G3x7KbC8F",
        "outputId": "f23e07ed-fdda-4aa9-9ed6-2749cbebd989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Krish', age='31', Experience='10', Salary='30000'),\n",
              " Row(Name='Sudhanshu', age='30', Experience='8', Salary='25000'),\n",
              " Row(Name='Sunny', age='29', Experience='4', Salary='20000')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELuBWSm4aPzb",
        "outputId": "1e6d64fb-42d6-4f96-c45b-66f31c74522c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SparkTutorial2"
      ],
      "metadata": {
        "id": "AbteF0PRc0Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "AtOO38QIdcKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "I-Ivc5x5dhAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('DataFrame').getOrCreate()"
      ],
      "metadata": {
        "id": "MiDNlZKsdm0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.option('header','true').csv('/content/sample_data/test1.csv',inferSchema=True)"
      ],
      "metadata": {
        "id": "Y6M4-ITMb238"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5HhvZatd02p",
        "outputId": "b6c93a74-547a-4c09-ee44-26270e6bfd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('/content/sample_data/test1.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQjhhHSyeUX6",
        "outputId": "0562f8df-9145-406c-c11b-aeb96b7f02a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkqkC19UfE14",
        "outputId": "396c56a3-e138-49da-ad61-0ede1e6a200c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdYP4MPFfO12",
        "outputId": "58a94a64-ed32-45ff-92a4-5a7634c20e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to get particular column data\n",
        "df_pyspark.select('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2OvqLU2fxPE",
        "outputId": "5238f06f-4358-460c-ea9b-703487e9e506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|     Name|\n",
            "+---------+\n",
            "|    Krish|\n",
            "|Sudhanshu|\n",
            "|    Sunny|\n",
            "|     Paul|\n",
            "|   Harsha|\n",
            "|  Shubham|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to pick multiple columns\n",
        "df_pyspark.select(['Name','Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdrXYzDSgQTv",
        "outputId": "264226aa-d19b-4ace-c012-cec5c3a60949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|     Name|Experience|\n",
            "+---------+----------+\n",
            "|    Krish|        10|\n",
            "|Sudhanshu|         8|\n",
            "|    Sunny|         4|\n",
            "|     Paul|         3|\n",
            "|   Harsha|         1|\n",
            "|  Shubham|         2|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To check data types \n",
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKQtTpMAgvc-",
        "outputId": "cb0b773e-9205-4fb5-b35d-9d7c17abdd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvc2Izb9hM8o",
        "outputId": "208bbdf7-a188-4671-e7f3-4e330f7fb83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-----------------+------------------+\n",
            "|summary|  Name|               age|       Experience|            Salary|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "|  count|     6|                 6|                6|                 6|\n",
            "|   mean|  null|26.333333333333332|4.666666666666667|21333.333333333332|\n",
            "| stddev|  null| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
            "|    min|Harsha|                21|                1|             15000|\n",
            "|    max| Sunny|                31|               10|             30000|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding columns in pyspark dataframe"
      ],
      "metadata": {
        "id": "pYHFobpviVT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=df_pyspark.withColumn('Experience after 2 years',df_pyspark['Experience']+2)"
      ],
      "metadata": {
        "id": "1HKdAfk1iPcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jncht-wOi40S",
        "outputId": "cfa4dba0-d0b1-4a67-96a7-3517a47b8613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+------------------------+\n",
            "|     Name|age|Experience|Salary|Experience after 2 years|\n",
            "+---------+---+----------+------+------------------------+\n",
            "|    Krish| 31|        10| 30000|                      12|\n",
            "|Sudhanshu| 30|         8| 25000|                      10|\n",
            "|    Sunny| 29|         4| 20000|                       6|\n",
            "|     Paul| 24|         3| 20000|                       5|\n",
            "|   Harsha| 21|         1| 15000|                       3|\n",
            "|  Shubham| 23|         2| 18000|                       4|\n",
            "+---------+---+----------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping columns"
      ],
      "metadata": {
        "id": "ZsJD_vQ0j1t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=df_pyspark.drop('Experience after 2 years')"
      ],
      "metadata": {
        "id": "1Z7imFBqjysi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMoT3A8AkKy6",
        "outputId": "5132bb60-31e5-496a-84ba-787d0d791e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename the column\n",
        "df_pyspark.withColumnRenamed('Name','New name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxzrcqlqntHN",
        "outputId": "f53f1c2c-8750-42b8-ae53-e05d7a191253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "| New name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PySpark Handling Missing Values\n",
        "---\n",
        "\n",
        "* -dropping columns\n",
        "* -dropping rows\n",
        "* -various parameters in dropping functionalities\n",
        "* -Handling missing values by mean, median, mode\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b8PsVjt3oMyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('practice').getOrCreate()"
      ],
      "metadata": {
        "id": "J-tULL2pn8kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('/content/sample_data/test2.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaB8C7vepgA5",
        "outputId": "7c15b0f5-a7fc-4f57-a045-33f5f3ea80fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete all the rows which contain null values\n",
        "df_pyspark.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NueMcspsHqG",
        "outputId": "76bc9732-231d-43b8-bf80-64a0ed790d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#delete all the rows which contains atleast one null value\n",
        "df_pyspark.na.drop(how='any').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7UsgJ0Isbgy",
        "outputId": "cf5ca558-c34c-4b97-82a3-6dd6b2be0e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the rows which contains all the null values\n",
        "df_pyspark.na.drop(how='all').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INBl6KAnt2vG",
        "outputId": "98c135b0-02bb-4f72-de72-33fed9292d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#delete the rows which does not contains atleast two non-null values\n",
        "df_pyspark.na.drop(how='any',thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H0m2YxOuI53",
        "outputId": "7452df4b-0141-436f-fe3e-6723fa6621bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the rows which contains Name column has null values\n",
        "df_pyspark.na.drop(how='any',subset=['Name']).show()\n",
        "\n",
        "#Delete the rows which contains Name column has null values\n",
        "df_pyspark.na.drop(how='any',subset=['Experience','age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Wrm2qdumgV",
        "outputId": "c21ed4ac-3d82-438c-820d-64c4c6a45f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "+---------+----+----------+------+\n",
            "\n",
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FILL"
      ],
      "metadata": {
        "id": "VqzO_2iL9r8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filling missing values\n",
        "df_pyspark.na.fill(999999999,['Experience','age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfF5cIfwvsu4",
        "outputId": "334c6703-fde7-4ec0-8599-ac884b46188e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------+------+\n",
            "|     Name|      age|Experience|Salary|\n",
            "+---------+---------+----------+------+\n",
            "|    Krish|       31|        10| 30000|\n",
            "|Sudhanshu|       30|         8| 25000|\n",
            "|    Sunny|       29|         4| 20000|\n",
            "|     Paul|       24|         3| 20000|\n",
            "|   Harsha|       21|         1| 15000|\n",
            "|  Shubham|       23|         2| 18000|\n",
            "|   Mahesh|999999999| 999999999| 40000|\n",
            "|     null|       34|        10| 38000|\n",
            "|     null|       36| 999999999|  null|\n",
            "+---------+---------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cPKTbZqzA5t",
        "outputId": "36bdcaa0-262b-40ad-e209-3bda6f824e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Imputer estimator completes missing values in a dataset, either using the mean or the median of the columns in which the missing values are located. The input columns should be of DoubleType or FloatType. ... Imputer can impute custom values other than 'NaN' by ."
      ],
      "metadata": {
        "id": "y-1kvFRS3aVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['age', 'Experience', 'Salary'], \n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "7R-1BsXrx-GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb1LpE5iyCWv",
        "outputId": "e356e20b-6bf5-4141-9fba-e3adc5636009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|null|      null| 40000|         28|                 5|         40000|\n",
            "|     null|  34|        10| 38000|         34|                10|         38000|\n",
            "|     null|  36|      null|  null|         36|                 5|         25750|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Filter Operation in PySpark"
      ],
      "metadata": {
        "id": "1sFknBBy9eig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('practice').getOrCreate()"
      ],
      "metadata": {
        "id": "7HQxiOUI9jsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('/content/sample_data/test1.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "fCIq_4g-9zbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgYYfYAb-zst",
        "outputId": "ac2d183c-e82b-4f70-f55c-688a62511ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.filter(\"Salary<=20000\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UnmJWOC-6br",
        "outputId": "dc7f93a2-6760-436d-d164-263f0f10cdf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.filter(\"Salary<=20000\").select(['Name','age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV6-y7RS_EDf",
        "outputId": "1176a4c0-8ac2-4f75-a5f5-4a0b6af5de8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|age|\n",
            "+-------+---+\n",
            "|  Sunny| 29|\n",
            "|   Paul| 24|\n",
            "| Harsha| 21|\n",
            "|Shubham| 23|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.filter(df_pyspark['Salary']<=20000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXDljilO_jGm",
        "outputId": "2538e1c9-ecce-4827-822e-9332426c6e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different filter conditions available like &, |, ==,~"
      ],
      "metadata": {
        "id": "ryb6T0r5BnQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shows data where salary>=15000 and salary<=20000\n",
        "df_pyspark.filter((df_pyspark['Salary']<=20000) & \n",
        "                  (df_pyspark['Salary']>=15000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gN4H5bIALQc",
        "outputId": "2ceb3850-a9e0-4080-a1f1-553597c9e1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Not operation in pyspark symbol for not \" ~ \"\n",
        "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUWIttyVA-UF",
        "outputId": "9ea67c7f-4ea5-4984-8324-746aa59892b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GroupBy and Aggregate in pyspark"
      ],
      "metadata": {
        "id": "dMuiV5N4ht9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InIgHL7ViSs4",
        "outputId": "917a49ae-98c0-4bd5-83dc-20356679a7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 56.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805911 sha256=5e40e929113c661e5505103708745421986e8e9af1b0ad72ff20d316bb6cb565\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "XJcbshX3htoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName(\"practice\").getOrCreate()"
      ],
      "metadata": {
        "id": "F_e_P8K6CcIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('/content/sample_data/test3.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "Mn6UICQskFSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_qGh82Wk8jJ",
        "outputId": "5417b3f8-16bc-4d14-c70d-3b2829c3aefc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Departments: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzfvmC_8lBTP",
        "outputId": "6d46332d-887d-4d2b-c844-5d87f08e59dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sum the salaries groupby name\n",
        "#aggregate function is always follwed by groupBy [aggregate functions like sum,avg...]\n",
        "df_pyspark.groupBy('Name').sum('salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IudWcBnvl63X",
        "outputId": "95d33f1c-f042-4a95-f0ac-9896d1afc6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      35000|\n",
            "|    Sunny|      12000|\n",
            "|    Krish|      19000|\n",
            "|   Mahesh|       7000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find average salary of each department\n",
        "df_pyspark.groupby('Departments').avg('salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdM4NK14mcF8",
        "outputId": "9acdc315-dd42-4656-87d7-b40fb3573f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#groupby departments which gives maximum salary\n",
        "sort_df=df_pyspark.groupby('Departments').sum('salary').show()"
      ],
      "metadata": {
        "id": "oyqSSZMZnjeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the count of people working in each department\n",
        "df_pyspark.groupby('Departments').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uva-IiHgov-Q",
        "outputId": "3ba9057f-94b0-4047-a49d-15b46b0adf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "| Departments|count|\n",
            "+------------+-----+\n",
            "|         IOT|    2|\n",
            "|    Big Data|    4|\n",
            "|Data Science|    4|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the count of people who salary is greater than or equal to 10000\n",
        "df_pyspark.filter('salary>=10000').groupby('salary').count().show()\n",
        "## 3 people have salary==10000 and 2 people have salary==20000 [grouping by salary]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3zuh6v6qCjV",
        "outputId": "2fdc1aa5-be45-4a87-b96f-fb374e5a7008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|salary|count|\n",
            "+------+-----+\n",
            "| 10000|    3|\n",
            "| 20000|    1|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Name').min().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KInFWMUor_oc",
        "outputId": "a4203f22-3f5d-42dd-fa02-9ed5cd59e439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|min(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|       5000|\n",
            "|    Sunny|       2000|\n",
            "|    Krish|       4000|\n",
            "|   Mahesh|       3000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Aggregate \n",
        "\n",
        "---\n",
        "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.agg.html?highlight=agg#pyspark.sql.DataFrame.agg\n"
      ],
      "metadata": {
        "id": "r_eqLd0d41L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##aggregate functiion\n",
        "##find sum of salary using agg function\n",
        "df_pyspark.agg({'salary':'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAp5zWiKtYcw",
        "outputId": "8507a696-9df8-43ec-9c37-abedf179897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(salary)|\n",
            "+-----------+\n",
            "|      73000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f\n",
        "df_pyspark.agg(f.min(df_pyspark['salary'])).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_eFf4sd5Bc-",
        "outputId": "269b5792-af97-4dd2-e4f3-3a80d04b828a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|min(salary)|\n",
            "+-----------+\n",
            "|       2000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aliasing"
      ],
      "metadata": {
        "id": "Hj6bbiZ381cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##alias\n",
        "\n",
        "df_aggregated=df_pyspark.groupBy('Name').agg(f.max(f.col('salary')).alias('maxSalary'),\n",
        "                                             f.min(df_pyspark['salary']).alias('minsalary'))\n",
        "df_aggregated.orderBy(f.asc('maxSalary')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw2LlU6y5zuT",
        "outputId": "1dbdfdfe-e9ff-4eae-a8d5-876dc0886057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+\n",
            "|     Name|maxSalary|minsalary|\n",
            "+---------+---------+---------+\n",
            "|   Mahesh|     4000|     3000|\n",
            "|    Sunny|    10000|     2000|\n",
            "|    Krish|    10000|     4000|\n",
            "|Sudhanshu|    20000|     5000|\n",
            "+---------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##sorting data\n",
        "\n",
        "---\n",
        "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.orderBy.html\n"
      ],
      "metadata": {
        "id": "Y8x_B3bcvDeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sorting the salaries in desciding order\n",
        "df_pyspark.sort(df_pyspark.salary.desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhY-dmVkuPUK",
        "outputId": "e8292953-7a4f-498e-885a-d3401b3287eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## other way sorting data\n",
        "df_pyspark.sort('salary',ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4LVL8NMvWyZ",
        "outputId": "ef6b94de-8834-4154-8f4c-a0bcc39e3b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "oOE4eNzpxZhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AUED1ZwyCjs",
        "outputId": "574740c8-9026-4676-ab97-c4644d063565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.orderBy([asc('salary'),'Name']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNRCGyqqxxPV",
        "outputId": "1a0da59e-b8f8-4fa8-db7a-036c8a3cdeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Sunny|    Big Data|  2000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Krish|Data Science| 10000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pyspark.sql.functions"
      ],
      "metadata": {
        "id": "n7Rn0RZo0uB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f"
      ],
      "metadata": {
        "id": "dlha3Ey8y4h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_sal_col=f.floor(df_pyspark['salary']/10)*10"
      ],
      "metadata": {
        "id": "y-dR0Ppfy3aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=df_pyspark.withColumn('updatedSal',updated_sal_col)"
      ],
      "metadata": {
        "id": "YzxLjDTWzqpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azVz8-N50GY9",
        "outputId": "b3b74a2b-c5fb-42ec-f116-b28c26a4e38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+----------+\n",
            "|     Name| Departments|salary|updatedSal|\n",
            "+---------+------------+------+----------+\n",
            "|    Krish|Data Science| 10000|       100|\n",
            "|    Krish|         IOT|  5000|        50|\n",
            "|   Mahesh|    Big Data|  4000|        40|\n",
            "|    Krish|    Big Data|  4000|        40|\n",
            "|   Mahesh|Data Science|  3000|        30|\n",
            "|Sudhanshu|Data Science| 20000|       200|\n",
            "|Sudhanshu|         IOT| 10000|       100|\n",
            "|Sudhanshu|    Big Data|  5000|        50|\n",
            "|    Sunny|Data Science| 10000|       100|\n",
            "|    Sunny|    Big Data|  2000|        20|\n",
            "+---------+------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=df_pyspark.drop('updatedSal')"
      ],
      "metadata": {
        "id": "tzhnn4EL0Yfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX1r0Cih0kzv",
        "outputId": "1801c5de-c3af-4f93-bbd2-ed6d70be1ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}